{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"badal patel - nlp_quiz1_f.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"G2CO2PQUGYPZ","colab":{}},"source":["import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pQok29kD8Ofk"},"source":["\n","\n","## Basic Text Processing\n","### Loading dataset\n","You need not mess with this code. Just run these cells to download the data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x-jb3k178NcU","colab":{}},"source":["!wget https://raw.githubusercontent.com/krishnamrith12/NotebooksNLP/master/Data/Tokenization/Chat1.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E_k4syLp2JjV","colab":{}},"source":["\n","import string\n","import matplotlib.pyplot as plt\n","import nltk\n","print('***********************************************************')\n","print('Your data successfully loaded.')\n","print('First 10 lines of conversation is shown:')\n","print('This is conversation between machine and user.')\n","print('***********************************************************')\n","with open(\"./Chat1.txt\") as myfile:\n","  for x in range(0,10):\n","    print(next(myfile))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Rln6iThhdYiD"},"source":["### Tokenize the data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qGq1SDMx8e8F"},"source":["\n","Suppose you are doing operations on string data named '*str = I love CODING.*'\n","\n","1.   Tokenize the data. For eg, output after this step will be ['I', 'love', 'CODING.']\n","2.   Lowercase the data . For ex, your output will be ['i' ,'love', 'coding.']\n","3. Remove the puctuations from data using . For eg, you will get output as ['i' ,'love', 'coding'] (Full stop is removed here). We have provided list of puctuations. So make sure that you remove all the punctuations. \n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1n3YDdWP2V__","colab":{}},"source":["f = open('./Chat1.txt','r')\n","content=f.read()\n","\n","# Punctuation list is as follows:\n","punc_list =['.',',',':','!','?','(',')',';']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"1hOjFeKATxo6","nbgrader":{"checksum":"330c0d3d591e8b84595cb92f4dd0a2e9","grade":false,"grade_id":"cell-879e4be9f192b139","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def tokenize(raw_data):\n","  \"\"\"\n","  Inputs:\n","    raw_data: string, raw text of the corpus\n","  Outputs:\n","    tokenized_data: list of strings, split raw_data on whitespace  \n","  \"\"\"\n","  # YOUR CODE HERE\n","  return tokenized_data  \n","\n","tokenized_data = tokenize(content)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"Wk-CNu-fUAFU","nbgrader":{"checksum":"eae1f181b6d5e3698830e8a4d7f93131","grade":true,"grade_id":"cell-7cf205456c5a3251","locked":true,"points":1,"schema_version":1,"solution":false},"colab":{}},"source":["\"\"\"Test tokenize\"\"\"\n","def test_tokenize():\n","  assert(tokenized_data[0:5] == ['User:', 'So', \"how's\", 'it', 'going?'])\n","  assert(len(tokenized_data) == 1013)\n","  print('Test passed', '\\U0001F44D')\n","test_tokenize()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"5UYCl331fR8s","nbgrader":{"checksum":"02dac91d63cedd5046f97a226c9fa412","grade":false,"grade_id":"cell-d2161471bc313ce0","locked":false,"schema_version":1,"solution":true},"colab":{"base_uri":"https://localhost:8080/","height":129},"outputId":"f7ade6a4-c867-4083-edf0-6a97ae2da54b","executionInfo":{"status":"error","timestamp":1561092420218,"user_tz":-330,"elapsed":1391,"user":{"displayName":"badal patel","photoUrl":"https://lh6.googleusercontent.com/-ewqN7WIMYFg/AAAAAAAAAAI/AAAAAAAABHQ/kIZDmRk3l48/s64/photo.jpg","userId":"03327391064734814444"}}},"source":["def lowercase_data(word):\n","  \"\"\"\n","  Inputs:\n","    word: a string\n","  Outputs:\n","    word_lowercase: a string (all alphabets in lowercase)\n","  \"\"\"\n","  # YOUR CODE HERE\n","  import pandas as pd\n","  import os\n","   folder = 'aclImdb'\n","labels = {'pos': 1, 'neg': 0}\n","df = pd.DataFrame()\n","for f in ('test', 'train'):    \n","    for l in ('pos', 'neg'):\n","        path = os.path.join(folder, f, l)\n","        for file in os.listdir (path) :\n","            with open(os.path.join(path, file),'r', encoding='utf-8') as infile:\n","                txt = infile.read()\n","            df = df.append([[txt, labels[l]]],ignore_index=True)\n","df.columns = ['review', 'sentiment']\n","  return word_lowercase\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ba6929594750>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    folder = 'aclImdb'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"50GXtr7YU6cI","nbgrader":{"checksum":"57ae44fb96fbf2e3c642fe80a6753d7d","grade":true,"grade_id":"cell-7cfca3bf3dcd93d1","locked":true,"points":2,"schema_version":1,"solution":false},"colab":{}},"source":["\"\"\"Test lowercase_data\"\"\"\n","def test_lowercase_data():\n","  assert(lowercase_data('Machine LEArning is AWesome;') == 'machine learning is awesome;')\n","  print('Test passed', '\\U0001F44D')\n","test_lowercase_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"tY4JnlMQfmXR","nbgrader":{"checksum":"476523fa117d71e57a9616665f1f9a59","grade":false,"grade_id":"cell-26309439d79eec9d","locked":false,"schema_version":1,"solution":true},"colab":{"base_uri":"https://localhost:8080/","height":129},"outputId":"4ead515e-9154-49f7-bc71-fea631f106c3","executionInfo":{"status":"error","timestamp":1561092451392,"user_tz":-330,"elapsed":1044,"user":{"displayName":"badal patel","photoUrl":"https://lh6.googleusercontent.com/-ewqN7WIMYFg/AAAAAAAAAAI/AAAAAAAABHQ/kIZDmRk3l48/s64/photo.jpg","userId":"03327391064734814444"}}},"source":["def remove_punctuation(word, punc_list):\n","  '''\n","  Inputs:\n","    punc_list: a list (containing punctuation characters)\n","    word: a string\n","  Outputs:\n","    word_no_punc: a string (without any punctuation characters)\n","  '''\n","  # YOUR CODE HERE\n","  from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","wordcloud = WordCloud().\n","generate_from_frequencies(frequency_dist)\n","plt.imshow(wordcloud)\n","plt.axis(\"off\")\n","plt.show()\n","  return word_no_punc"],"execution_count":2,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-50dc6a4af029>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    wordcloud = WordCloud().\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"oToxFcnBXDk8","nbgrader":{"checksum":"aba1c7cd6a3043669d577c12e1906706","grade":true,"grade_id":"cell-c7c5ac2cfff31a2e","locked":true,"points":3,"schema_version":1,"solution":false},"colab":{}},"source":["\"\"\"Test remove_punctuation\"\"\"\n","def test_remove_punctuation():\n","  assert(remove_punctuation('mac.hin;e le,ar.ning is? awe!some;', punc_list) == 'machine learning is awesome')\n","  assert(remove_punctuation(tokenized_data[4], punc_list) == 'going')\n","  print('Test passed', '\\U0001F44D')\n","test_remove_punctuation()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"HK0BX7xD_h-w","nbgrader":{"checksum":"cc663cbfeb52549f70b56db1b09885a1","grade":false,"grade_id":"cell-656370f38a73238c","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def preprocess(content):\n","  \"\"\"\n","  Inputs:\n","    content: a string\n","  Outputs:\n","    wordlist: a list of strings\n","    \n","  Action:\n","    1. Preprocess the string 'content' using the functions created above (tokenize, lowercase and remove_punctuation) \n","    2. Store it in a list 'wordlist'\n","    \n","  \"\"\"\n","  # YOUR CODE HERE\n","  return wordlist\n","\n","wordlist = preprocess(content)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"GA5JqHReYdmz","nbgrader":{"checksum":"a97eef6fd30ae408844686f3675579ba","grade":true,"grade_id":"cell-7ac5de7d7e634c5e","locked":true,"points":3,"schema_version":1,"solution":false},"colab":{}},"source":["\"\"\"Test preprocess\"\"\"\n","def test_preprocess():\n","  assert(len(wordlist) == 1013)\n","  print('Test passed', '\\U0001F44D')\n","test_preprocess()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FoXZvZUMAG48"},"source":["### Plot the frequency of words\n","You need to plot the frequncy of words using function provided. <br>\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ol_OktB51vH-","colab":{}},"source":["def plot_frequency(y):\n","  N = len(y)\n","  x = range(N)\n","  width = 1/0.5\n","  plt.bar(x, y, width, color=\"blue\")\n","  plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZVur7GZXJxH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"858c66b7-64d6-4d6e-90a1-d15a4c056289","executionInfo":{"status":"error","timestamp":1561092512808,"user_tz":-330,"elapsed":1011,"user":{"displayName":"badal patel","photoUrl":"https://lh6.googleusercontent.com/-ewqN7WIMYFg/AAAAAAAAAAI/AAAAAAAABHQ/kIZDmRk3l48/s64/photo.jpg","userId":"03327391064734814444"}}},"source":["plotdata()"],"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2983a4cd64a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'plotdata' is not defined"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F_9z_wNzFvMh"},"source":["### To do\n","1) Find out count of each word using  function and store this  in list named word_count using <br>\n","2) Pass the word_count list to function to plot the frequency plot.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"Bjb8Iyz-5Kn7","nbgrader":{"checksum":"ddee3291bc0ca973030fd0233578eac4","grade":false,"grade_id":"cell-74a2a6d1b947fd18","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def frequency(wordlist):\n","  \"\"\"\n","  Inputs:\n","    wordlist: a list of string\n","  Outputs:\n","    word_count: a list, frequency of all the items in wordlist\n","  \"\"\"\n","  # YOUR CODE HERE\n","  return word_count\n","\n","word_count = frequency(wordlist)\n","plot_frequency(word_count)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"qyFnPxhJaPw8","nbgrader":{"checksum":"e64540120298824fc42229b39835af80","grade":true,"grade_id":"cell-a5201c484d0a6d62","locked":true,"points":3,"schema_version":1,"solution":false},"colab":{}},"source":["\"\"\"Test frequency\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HaiGyFdMgQnj"},"source":["## (1) Cosine Similarity\n","When we have word vectors, we need a way to quantify the similarity between individual words, according to these vectors. One such metric is cosine-similarity. We will be using this to find words that are \"close\" and \"far\" from one another.\n","\n","We can think of n-dimensional vectors as points in n-dimensional space. If we take this perspective, *L1* and *L2* Distances help quantify the amount of space \"*we must travel\"* to get between these two points. \n","\n","Another approach is to examine the angle between two vectors. Instead of computing the actual angle, we can leave the similarity in terms of  similarity=cos(Θ) . Formally, the Cosine Similarity  s  between two vectors  p  and  q  is defined as:\n","\n","$s = \\frac{p⋅q}{||p||||q||} $, where s∈[−1,1]<br>\n","You need to implement this function."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"-SfyCjuDgWR6","nbgrader":{"checksum":"bc524554866224301d947cb4069a7b4f","grade":false,"grade_id":"cell-0c747a3b2f96a69e","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["import math\n","def cosine_similarity(v1,v2):\n","    \"\"\"\n","    Input:\n","        v1: list of floats,\n","        v2: list of floats, same length as v1\n","        \n","    Output:\n","        cs: single floating point value, cosine similarity of v1 and v2 as defined above\n","        /\n","    \"\"\"\n","    # YOUR CODE HERE\n","    return cs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"ub6xDoSWgaqS","nbgrader":{"checksum":"6ed71d817b1bec615bbfd8e2b9320d46","grade":true,"grade_id":"cell-a7a84c46a5167540","locked":true,"points":4,"schema_version":1,"solution":false},"colab":{}},"source":["'''test for cosine_similarity'''\n","v1,v2 = [3, 45, 7, 2], [2, 5.4, 13, 15]\n","v = cosine_similarity(v1,v2)\n","assert np.isclose(v, 0.39187288174224344, 0.0001)\n","\n","print('Test passed', '\\U0001F44D')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sCU5rscXGUxK"},"source":["### Most similar word\n","Implement the function, given a word \"*x*\", it will return most similar word from first column of data, based on similarity measure. <br>\n","For example, for most similar word to *king* could be *man*. <br>"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"KAaZGulSJjBm","nbgrader":{"checksum":"3760c5dce4bac64c7a369970b9f14055","grade":false,"grade_id":"cell-7882664ff09b1996","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["def most_similar(input_word,wordvec_dict):\n","  \"\"\"\n","  Input:\n","      input_word: any word\n","      wordvec_dict: dictionary of word vectors(list of floats), where a word is the key and its word_vector is the value\n","      \n","  Output:\n","      out: string, the word in wordvec_dict most similar to 'word'\n","  \"\"\"\n","  # YOUR CODE HERE\n","  return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"vxytbub2Jooo","nbgrader":{"checksum":"835796e8ec0c7300555b3efcc638aa59","grade":true,"grade_id":"cell-00e66f0dda9fcd70","locked":true,"points":4,"schema_version":1,"solution":false},"colab":{}},"source":["\n","word_vec_dict = {\n","    'princess': [-1.720603,\t-3.560657],\n","    'queen': [-0.722603,\t-1.232549],\n","    'man':\t[-0.370373,\t0.576843],\n","    'boy':\t[-1.693504,\t0.719822]\n","\n","}\n","\n","'''test for most_similar'''\n","assert most_similar('queen', word_vec_dict) == 'princess'\n","print('Test passed', '\\U0001F44D')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WqeQHiW-K45r","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}